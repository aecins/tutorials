{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aecins/tutorials/blob/main/least_squares/ordinary_least_squares.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2263e7ab",
      "metadata": {
        "id": "2263e7ab"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.linalg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f3ee3a",
      "metadata": {
        "id": "b6f3ee3a"
      },
      "source": [
        "# Create a linear least squares problem\n",
        "We setup a simple [linear least squares problem](https://en.wikipedia.org/wiki/Linear_regression) by creating values for:\n",
        "- true parameter values $x$ (sampled from uniform distribution)\n",
        "- independent variables $A$ (sampled from uniform distribution)\n",
        "- dependent variables $b$ (constructed as $Ax + \\mathcal{N}(0, I * \\sigma_b)$, i.e. residuals are uncorrelated and have the same variance)\n",
        "\n",
        "This satisfies the assumptions on the measurement errors of ordinary least squares:\n",
        "- Measurement errors are uncorrelated\n",
        "- Measurement errors have the same variance (this property is called [homoscedasticity](https://en.wikipedia.org/wiki/Homoscedasticity))\n",
        "- Measurement errors are zero mean normally distributed\n",
        "\n",
        "These assumptions can be summarized as a single statement:\n",
        "- measurement error vector is drawn from a multivariate Gaussian distribution with zero mean and a covariance matrix of $I * \\sigma_b^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "395016c8",
      "metadata": {
        "id": "395016c8"
      },
      "outputs": [],
      "source": [
        "# Function that generates random values drawn from uniform distribution with a given range.\n",
        "def generate_random_uniform(y_size, x_size, value_min, value_max):\n",
        "    assert(value_max > value_min)\n",
        "\n",
        "    values = np.random.rand(y_size, x_size)\n",
        "    values = values * (value_max - value_min)\n",
        "    values = values + value_min\n",
        "\n",
        "    return values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0911e759",
      "metadata": {
        "id": "0911e759",
        "outputId": "da993a77-c158-465c-b75e-e56b5e999d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.72034786]\n",
            " [-3.52351843]\n",
            " [-7.63227028]]\n"
          ]
        }
      ],
      "source": [
        "# Create true parameters of a linear least squares problem by sampling them uniformly\n",
        "# in the range [-X_TRUE_MAGNITUDE; X_TRUE_MAGNITUDE]\n",
        "NUM_PARAMETERS = 3\n",
        "X_TRUE_MAGNITUDE = 10\n",
        "\n",
        "x_true = generate_random_uniform(NUM_PARAMETERS, 1, -X_TRUE_MAGNITUDE, X_TRUE_MAGNITUDE)\n",
        "print(x_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "05b98665",
      "metadata": {
        "id": "05b98665"
      },
      "outputs": [],
      "source": [
        "# Function that generates random independent variables (A) and corresponding noisy dependent variables (b)\n",
        "# for a linear least squares problem.\n",
        "def generate_Ab(x_true, num_measurements, A_magnitude, b_noise_sigma):\n",
        "    # First generate independent variables aka A matrix.\n",
        "    # These are generated from a uniform distribution in the range [-A_magnitude; A_magnitude]\n",
        "    A = generate_random_uniform(NUM_MEASUREMENTS, NUM_PARAMETERS, -A_magnitude, A_magnitude)\n",
        "\n",
        "    # Next generate dependent variables aka vector b.\n",
        "    # These are generated as values predicted by the true values of the model + measurement noise\n",
        "    measurement_noise = (np.random.normal(0, b_noise_sigma, [num_measurements, 1]))\n",
        "    b = A.dot(x_true) + measurement_noise\n",
        "\n",
        "    return [A, b]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8aa98c55",
      "metadata": {
        "id": "8aa98c55"
      },
      "outputs": [],
      "source": [
        "# Generate measurements.\n",
        "NUM_MEASUREMENTS = 100000\n",
        "A_MAGNITUDE = 0.1\n",
        "B_NOISE_SIGMA = 10\n",
        "\n",
        "[A, b] = generate_Ab(x_true, NUM_MEASUREMENTS, A_MAGNITUDE, B_NOISE_SIGMA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd1f9734",
      "metadata": {
        "id": "bd1f9734"
      },
      "source": [
        "## Validate residuals\n",
        "The vector of residuals is defined as:\n",
        "$$\n",
        "r = Ax - b\n",
        "$$\n",
        "We can check that the system was constructed correctly by checking that residuals evaluated at ground truth parameter values have the same distribution as the noise that was added to dependent measurements $b$:\n",
        "$$\n",
        "b = Ax_{true} + \\mathcal{N}(0, \\sigma_b) \\\\\n",
        "r = Ax_{true} - b \\\\\n",
        "r \\sim \\mathcal{N}(0, \\sigma_b)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b368c587",
      "metadata": {
        "scrolled": false,
        "id": "b368c587",
        "outputId": "72cda9d9-b6b7-49b9-9ea1-ddcb7e5449d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics of residuals evaluated at true parameter values\n",
            "mean  : estimated -0.053, expected 0.000\n",
            "sigma : estimated 10.002, expected 10.000\n"
          ]
        }
      ],
      "source": [
        "# Check that the residuals evaluated at true parameter values have the same statistics as measurement noise.\n",
        "residuals_true = A.dot(x_true) - b\n",
        "print(\"Statistics of residuals evaluated at true parameter values\")\n",
        "print(\"mean  : estimated {:.3f}, expected {:.3f}\".format(np.mean(residuals_true), 0))\n",
        "print(\"sigma : estimated {:.3f}, expected {:.3f}\".format(np.std(residuals_true), B_NOISE_SIGMA))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b9cc651",
      "metadata": {
        "id": "3b9cc651"
      },
      "source": [
        "## Jacobian\n",
        "[Jacobian](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant) of a vector-valued function is defined as a matrix of partial derivatives of the value of the function with respect to its parameters . In the context of optimization we are interested in the Jacobian of the residuals since the tells us how the residuals change as we change the parameters.\n",
        "\n",
        "For a linear least squares problem we have:\n",
        "$$\n",
        "\\begin{align*}\n",
        "r(x) & = Ax - b \\\\\n",
        "J & = \\begin{bmatrix}\\dfrac{dr_i}{dx_j}\\end{bmatrix} = A\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "### Validating Jacobian\n",
        "For any linear function $f(x)$ with Jacobian $J$ we can predict the value of a function at one point given the value of the function at another point:\n",
        "$$\n",
        "f(x) = f(y) + J * (x - y) = f(y) + J \\Delta\n",
        "$$\n",
        "where $\\Delta = x-y$ is a vector and $J \\Delta$ is a matrix vector product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "11e0cb35",
      "metadata": {
        "id": "11e0cb35",
        "outputId": "5d71a730-f641-459f-b82d-709c23e4e5a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum norm of the difference between true and predicted values of the residual: 0.00\n"
          ]
        }
      ],
      "source": [
        "# Validate Jacobian of the residual function.\n",
        "NUM_JACOBIAN_TESTS = 100\n",
        "max_value_difference = 0\n",
        "\n",
        "# Calculate Jacobian.\n",
        "J = A\n",
        "\n",
        "for i in range(NUM_JACOBIAN_TESTS):\n",
        "    # Create two random parameter values.\n",
        "    x = generate_random_uniform(NUM_PARAMETERS, 1, -X_TRUE_MAGNITUDE, X_TRUE_MAGNITUDE)\n",
        "    y = generate_random_uniform(NUM_PARAMETERS, 1, -X_TRUE_MAGNITUDE, X_TRUE_MAGNITUDE)\n",
        "\n",
        "    # Calculate residuals\n",
        "    r_x = A.dot(x) - b\n",
        "    r_y = A.dot(y) - b\n",
        "\n",
        "    # Calculate predicted residual\n",
        "    delta = x - y\n",
        "    r_x_predicted = r_y + J.dot(delta)\n",
        "    max_value_difference = max(max_value_difference, np.linalg.norm(r_x - r_x_predicted))\n",
        "\n",
        "print(\"Maximum norm of the difference between true and predicted values of the residual: {:.2f}\".format(max_value_difference))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d4b055a",
      "metadata": {
        "id": "0d4b055a"
      },
      "source": [
        "#Solving linear least squares problem\n",
        "\n",
        "## Normal equations\n",
        "Typically there does not exist a solution to parameters $x^*$ that exactly satisfies the system of equations $Ax = b$. Instead we want to find a solution that satisfies the equations \"best\" in the sense of minimizing the sum of squared residuals:\n",
        "$$\\DeclareMathOperator*{\\argmin}{\\arg\\!\\min}\n",
        "x^* = \\argmin_x ||Ax - b||^2$$\n",
        "This problem has a unique solution that is obtained by solving a system of linear equations called the [normal equations](https://en.wikipedia.org/wiki/Ordinary_least_squares#Matrix/vector_formulation):\n",
        "$$A^TA x^* = A^Tb$$\n",
        "[TODO: add link to normal equations derivation]\n",
        "\n",
        "### Information matrix / Hessian\n",
        "$A^TA$ is also known as the information matrix $\\mathcal{I}$. It can be interpreted as the matrix of second order partial derivatives of the least squares cost function with respect to parameters $x$. In other words $A^TA$ is the [Hessian](https://en.wikipedia.org/wiki/Hessian_matrix) of the cost function:\n",
        "$$\n",
        "f(x) = ||Ax - b||^2 \\\\\n",
        "H = \\begin{bmatrix} \\dfrac{\\partial f}{\\partial x_i  \\partial x_j} \\end{bmatrix} = A^TA\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## Solving by inverting the information matrix\n",
        "Optimal solution to the problem can be found by inverting the information matrix:\n",
        "\n",
        "$$x^* = (A^T A)^{-1} A^T b$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "98735167",
      "metadata": {
        "id": "98735167",
        "outputId": "288ea055-4c46-4e0a-d695-fdcfb6dc62c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.79 ms, sys: 5.21 ms, total: 7.99 ms\n",
            "Wall time: 9.09 ms\n"
          ]
        }
      ],
      "source": [
        "# Solve linear least squares problem by inverting the information matrix.\n",
        "def solve_using_matrix_inverse(A, b):\n",
        "    I = A.transpose().dot(A)\n",
        "    I_inv = np.linalg.inv(I)\n",
        "    Atb = (A.transpose()).dot(b)\n",
        "    return np.matmul(I_inv, Atb)\n",
        "\n",
        "%time x_estimated = solve_using_matrix_inverse(A, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c8820bd1",
      "metadata": {
        "id": "c8820bd1",
        "outputId": "66df1b9a-f0d0-49e7-9d7e-cda7e3cf7c51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error of paramters estimated using information matrix inverse:\n",
            " 0.334697\n"
          ]
        }
      ],
      "source": [
        "# Calculate RMSE of parameters.\n",
        "def parameter_rmse(x_estimated, x_true):\n",
        "    assert(len(x_estimated) == len(x_true))\n",
        "    return np.linalg.norm(x_estimated - x_true) / len(x_estimated)\n",
        "\n",
        "rmse = parameter_rmse(x_estimated, x_true)\n",
        "print(\"Root Mean Squared Error of paramters estimated using information matrix inverse:\\n {:f}\".format(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2936224d",
      "metadata": {
        "id": "2936224d"
      },
      "source": [
        "## Solve using factorization of the information matrix\n",
        "Using least squares problems by inverting the information matrix has several downsides:\n",
        "- inverting large matrices is slow\n",
        "- inverting matrices is numerically unstable\n",
        "\n",
        "Alternatively, we can take advantage of the special structure of the information matrix. Since $\\mathcal{I} = A^TA$ is a real summetric matrix we can factorize it using the [LDL decomposition](https://en.wikipedia.org/wiki/Cholesky_decomposition#LDL_decomposition):\n",
        "$$A^TA = LDL^T$$\n",
        "where $L$ is a lower diagonal matrix with unit diagonal and $D$ is a diagonal matrix. Normal equations become:\n",
        "$$\n",
        "LDL^Tx^* = A^Tb\n",
        "$$\n",
        "The solution can be obtained by solving a series of [systems of linear equations](https://en.wikipedia.org/wiki/System_of_linear_equations) (not to be confused with linear least squares problems!):\n",
        "1. $Ly_1 = A^Tb$ (solved using [forward substituition](https://en.wikipedia.org/wiki/Triangular_matrix#Forward_and_back_substitution) since $L$ is lower triangular)\n",
        "1. $Dy_2 = y_1$ (solved by element-wise division since $D$ is a diagonal matrix)\n",
        "1. $L^Tx^* = y_2$ (solved using [back substituition](https://en.wikipedia.org/wiki/Triangular_matrix#Forward_and_back_substitution) since $L^T$ is upper triangular)\n",
        "\n",
        "Note that none of the steps in the solution (calculating $A^TA$ and $A^Tb$, computing the LDL factorization of $A^TA$) and solving the resulting linear system of equations) require expensive operations like taking matrix inverse, squaring or taking square roots. In fact they only requires multiply-adds. This makes this approach both fast and numerically stable.\n",
        "\n",
        "$LDL^T$ solver is implemeted in the [Eigen C++ library](https://eigen.tuxfamily.org/dox/classEigen_1_1LDLT.html#aa257dd7a8acf8b347d5a22a13d6ca3e1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ca39a52c",
      "metadata": {
        "id": "ca39a52c",
        "outputId": "41bc9792-afad-42c2-d875-f77cd0cc60c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.69 ms, sys: 10.2 ms, total: 19.9 ms\n",
            "Wall time: 24.9 ms\n",
            "Root Mean Squared Error of paramters estimated using LDL factorization:\n",
            " 0.334697\n"
          ]
        }
      ],
      "source": [
        "# Solve linear least squares problem using LDL factorization.\n",
        "def solve_using_ldl(A, b):\n",
        "    # Calculate LDL factorization of the information matrix\n",
        "    I = A.transpose().dot(A)\n",
        "    [L, D, perm] = scipy.linalg.ldl(I)\n",
        "\n",
        "    # Solve Ly_1 = A^Tb\n",
        "    y1 = scipy.linalg.solve_triangular(L, A.transpose().dot(b), trans=0, lower=True, unit_diagonal=True)\n",
        "\n",
        "    # Solve Dy2 = y1\n",
        "    diagonal = np.diagonal(D).reshape(-1, 1)\n",
        "    y2 = np.divide(y1, diagonal)\n",
        "\n",
        "    # Solve L^Tx^* = y_2\n",
        "    return scipy.linalg.solve_triangular(L.transpose(), y2, trans=0, lower=False, unit_diagonal=True)\n",
        "\n",
        "%time x_estimated = solve_using_ldl(A, b)\n",
        "rmse = parameter_rmse(x_estimated, x_true)\n",
        "print(\"Root Mean Squared Error of paramters estimated using LDL factorization:\\n {:f}\".format(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d25ef9c",
      "metadata": {
        "id": "7d25ef9c"
      },
      "source": [
        "#### Note on the runtime\n",
        "The algorithm used for calcularing matrix inverse in `numpy.linalg.inv` is optimized for performance. Hence we don't see a large improvement in the runtime between inverse information matrix and LDLT solvers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d744c68f",
      "metadata": {
        "id": "d744c68f"
      },
      "source": [
        "# Solution covariance\n",
        "## Estimating covariance using information matrix\n",
        "Given a linear least squares problem $Ax = b$ the covariance matrix of the solution can be estimated as:\n",
        "$$cov(x^*) = (A^T A)^{-1} \\sigma_b^2$$\n",
        "where $\\sigma_b$ is the standard deviation of the residuals [[proof](https://github.com/aecins/tutorials/blob/main/least_squares/least_squares_covariance_derivation.ipynb)].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6bc51f7e",
      "metadata": {
        "id": "6bc51f7e",
        "outputId": "b65d4782-1a45-4468-ba7a-3bbd981efd60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution covariance estimated numerically from a single problem:\n",
            "[[ 0.299  0.001  0.001]\n",
            " [ 0.001  0.300  0.001]\n",
            " [ 0.001  0.001  0.300]]\n"
          ]
        }
      ],
      "source": [
        "# Calculate the covariance matrix of the estimated parameters.\n",
        "x_estimated_covariance = np.linalg.inv(np.matmul(A.transpose(), A)) * B_NOISE_SIGMA * B_NOISE_SIGMA\n",
        "print(\"Solution covariance estimated numerically from a single problem:\")\n",
        "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
        "print(x_estimated_covariance)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ac8b488",
      "metadata": {
        "id": "5ac8b488"
      },
      "source": [
        "## Estimating covariane using bootstrap\n",
        "Another way to estimate covariance of the solution is to use a bootstrap method. The high-level idea of this method is to:\n",
        "1. generate multiple optimization problems that are \"equivalent\" to the original problem\n",
        "2. solve these problems and get multiple estimates of the solution $x$\n",
        "3. calculate the covariance matrix of the obtained solutionsand then calculate\n",
        "\n",
        "Multiple ways were proposed to generate \"equivalent\" optimization problems [[wiki](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))]. One way is to resample with replacement the constraints in the optimization problems. That corresponds to resampling the rows in the matrix $A$ and corresponding values in $b$. In our case, since we are using synthetic data that is generated from known distributions - we can simply generate new values for $A$ and $b$ by drawing them from the same distributions as in the original problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0a82fcb6",
      "metadata": {
        "id": "0a82fcb6",
        "outputId": "8d532138-28b4-49dc-feb0-48855563e7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "93bd97b01dd94ef2841263da22522e06",
            "6262a44711ed4560ae2972eb15da0e3b",
            "d115f183d34a47c6b492cad60b7120fb",
            "68327e6c93c342ad80b546b3b35bf991",
            "1e1300ae02ce44c38f42c881dc7823fb",
            "0c38fe3a62584513bbb1f1a727c31683",
            "5781ca3c05f84ab499af2adf9affbbeb",
            "eb78ecb8ba80493c8476b08267f0e952",
            "e5b0be64ad054db5b51f34c61f78e779",
            "39c4ed8ac3af4c36b9aa49df71f014a7",
            "7bd81c1c25de4ecb81dbca01bfdb9853"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93bd97b01dd94ef2841263da22522e06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution covariance estimated using bootstrap:\n",
            "[[ 0.305  0.001  0.002]\n",
            " [ 0.001  0.301  0.003]\n",
            " [ 0.002  0.003  0.300]]\n",
            "CPU times: user 2min 36s, sys: 2min 15s, total: 4min 51s\n",
            "Wall time: 3min 10s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Calculate the covariance matrix using bootstrap.\n",
        "# We create multiple problems with the same true solution but different measurements (A, b)(same measurement noise).\n",
        "# We then calculate the covariance matrix of the solutions to these problems.\n",
        "NUM_BOOTSTRAP_ITERATIONS = 10000\n",
        "x_estimates = np.zeros((NUM_PARAMETERS, NUM_BOOTSTRAP_ITERATIONS))\n",
        "for i in tqdm(range(NUM_BOOTSTRAP_ITERATIONS)):\n",
        "    # Generate A and b.\n",
        "    [A, b] = generate_Ab(x_true, NUM_MEASUREMENTS, A_MAGNITUDE, B_NOISE_SIGMA)\n",
        "\n",
        "    # Solve.\n",
        "    x_estimated = solve_using_matrix_inverse(A, b)\n",
        "\n",
        "    # Append to solutions\n",
        "    x_estimates[:, i] = x_estimated[:, 0]\n",
        "\n",
        "print(\"Solution covariance estimated using bootstrap:\")\n",
        "print(np.cov(x_estimates))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analytical derivation of solution covariance\n",
        "Since we know how we generated the the values of the elements of the matrix $A$ for our problem, we can find the covariance of the solution analytically by calculating the expected value of the covariance matrix:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "𝔼[cov(x^*)] &= 𝔼[(A^T A)^{-1} \\sigma_b^2] \\\\\n",
        "            &= 𝔼[(A^T A)^{-1}] \\sigma_b^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "Let's assume that the following is true: $𝔼[M^{-1}] = 𝔼[M]^{-1}$. I do not have a proof for this but I suspect that this is true for $A^TA$. If that is true, then we have [TODO: prove why this is the case]:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "𝔼[cov(x^*)] &= 𝔼[(A^T A)^{-1}] \\sigma_b^2 \\\\\n",
        "            &= 𝔼[A^T A]^{-1} \\sigma_b^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "Let's consider the random matrix $A$. It's size is $n \\times m$ where $n$ is the number of paramters in the problem and $m$ is the number of measurements. For our problem $A$ is constructed by drawing values randomly from a zero-mean uniform distribution:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "A & =\n",
        "\\begin{bmatrix}\n",
        "| & | & \\cdots & | \\\\\n",
        "a_0 & a_1 & \\cdots & a_n \\\\\n",
        "| & | & \\cdots & | \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "a_{ij} & \\sim \\textit{U}(-A_{mag}, +A_{mag})\n",
        "\\end{aligned}\n",
        "$$\n",
        "Next let's consider the random matrix $A^T A$. Each of its elements is a dot product of the columns of the matrix $A$. The expected value of this random matrix is equal to the expected values of its elements:\n",
        "$$\n",
        "\\newcommand{\\vertbar}{\\rule[-1ex]{0.5pt}{2.5ex}}\n",
        "\\begin{aligned}\n",
        "A^T A & =\n",
        "\\begin{bmatrix}\n",
        "{a_0}^Ta_0 & \\cdots & {a_n}^Ta_0 \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "{a_0}^Ta_n & \\cdots & {a_n}^Ta_n \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "𝔼[A^T A] & =\n",
        "\\begin{bmatrix}\n",
        "𝔼[{a_0}^Ta_0] & \\cdots & 𝔼[{a_n}^Ta_0] \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "𝔼[{a_0}^Ta_n] & \\cdots & 𝔼[{a_n}^Ta_n] \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "         & =\n",
        "\\begin{bmatrix}\n",
        "\\dfrac{A_{mag}^2}{3} * m & \\cdots & 0 \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "0 & \\cdots & \\dfrac{A_{mag}^2}{3} * m \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "         & =\n",
        "\\dfrac{A_{mag}^2}{3} * m * I_{n \\times n} \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The values of the elements of this matrix are as follows:\n",
        "* diagonal elements have non-zero values $𝔼[{a_i}^Ta_i] = \\dfrac{A_{mag}^2}{3} * m$ since:\n",
        "  1. Expected value of a square of a zero-mean uniformly distributed random variable is $𝔼[x^2] = \\dfrac{A_{mag}^2}{3}$ for $x \\sim \\textit{U}(-A_{mag}, +A_{mag})$ [[source](https://www.wolframalpha.com/input?i=expected+value+of+x%5E2%2C+x+uniform)]\n",
        "  2. The dot product ${a_i}^Ta_i$ is a sum of $m$ such squares.\n",
        "* off-diagonal elements are zero since:\n",
        "  1. all elements of $A$ are independent of each other and for two independent random variables hence $𝔼[x * y] = 𝔼[x] * 𝔼[y]$\n",
        "  2. all elements of $A$ are zero mean since $a_{ij} \\sim \\textit{U}(-A_{mag}, +A_{mag})$\n",
        "Plugging this in to previous equation we get:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "𝔼[cov(x^*)] &= 𝔼[A^T A]^{-1} \\sigma_b^2 \\\\\n",
        "            &=\n",
        "\\left( \\dfrac{A_{mag}^2}{3} * m * I_{n \\times n} \\right)^{-1} \\sigma_b^2\\\\\n",
        "            &=\n",
        "\\dfrac{3}{A_{mag}^2*m} * I_{n \\times n} * \\sigma_b^2\n",
        "\\end{aligned}\n",
        "$$"
      ],
      "metadata": {
        "id": "PwS_csvmV0sM"
      },
      "id": "PwS_csvmV0sM"
    },
    {
      "cell_type": "code",
      "source": [
        "covariance_analytical = 3 / (A_MAGNITUDE * A_MAGNITUDE * NUM_MEASUREMENTS) * np.eye(NUM_PARAMETERS, NUM_PARAMETERS) * B_NOISE_SIGMA * B_NOISE_SIGMA\n",
        "print(\"Solution covariance estimated analytically:\")\n",
        "print(covariance_analytical)"
      ],
      "metadata": {
        "id": "DF3VwgVN6swc",
        "outputId": "5efeff55-9c1a-4bcf-c097-3ac1ee8b42af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DF3VwgVN6swc",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution covariance estimated analytically:\n",
            "[[ 0.300  0.000  0.000]\n",
            " [ 0.000  0.300  0.000]\n",
            " [ 0.000  0.000  0.300]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93bd97b01dd94ef2841263da22522e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6262a44711ed4560ae2972eb15da0e3b",
              "IPY_MODEL_d115f183d34a47c6b492cad60b7120fb",
              "IPY_MODEL_68327e6c93c342ad80b546b3b35bf991"
            ],
            "layout": "IPY_MODEL_1e1300ae02ce44c38f42c881dc7823fb"
          }
        },
        "6262a44711ed4560ae2972eb15da0e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c38fe3a62584513bbb1f1a727c31683",
            "placeholder": "​",
            "style": "IPY_MODEL_5781ca3c05f84ab499af2adf9affbbeb",
            "value": "100%"
          }
        },
        "d115f183d34a47c6b492cad60b7120fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb78ecb8ba80493c8476b08267f0e952",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5b0be64ad054db5b51f34c61f78e779",
            "value": 10000
          }
        },
        "68327e6c93c342ad80b546b3b35bf991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39c4ed8ac3af4c36b9aa49df71f014a7",
            "placeholder": "​",
            "style": "IPY_MODEL_7bd81c1c25de4ecb81dbca01bfdb9853",
            "value": " 10000/10000 [03:10&lt;00:00, 63.47it/s]"
          }
        },
        "1e1300ae02ce44c38f42c881dc7823fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c38fe3a62584513bbb1f1a727c31683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5781ca3c05f84ab499af2adf9affbbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb78ecb8ba80493c8476b08267f0e952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b0be64ad054db5b51f34c61f78e779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39c4ed8ac3af4c36b9aa49df71f014a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd81c1c25de4ecb81dbca01bfdb9853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}