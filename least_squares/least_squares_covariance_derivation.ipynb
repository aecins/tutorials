{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aecins/tutorials/blob/main/least_squares/least_squares_covariance_derivation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b54030c",
      "metadata": {
        "id": "6b54030c"
      },
      "source": [
        "# Covariance of a random variable transformed by a linear transform\n",
        "Consider a random variable $\\mathbf{x}$ with covariance matrix $cov(\\mathbf{x}) = \\Sigma$. Now consider a new random variable $\\mathbf{y} = M\\mathbf{x}$ that is obtained by applying a fixed linear transformation $M$ to $\\mathbf{x}$. The covariance of $\\mathbf{y}$ is:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "cov(\\mathbf{y}) &= cov(M\\mathbf{x}) \\\\\n",
        "                &= M cov(\\mathbf{x}) M^T \\\\\n",
        "                &= M \\Sigma M^T\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This property can be proven by expanding the definition of covariance matrix:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "cov(M\\mathbf{x})\n",
        "&= ùîº[(M\\mathbf{x} - ùîº[M\\mathbf{x}])(M\\mathbf{x} - ùîº[M\\mathbf{x}])^T] \\\\\n",
        "&= ùîº[(M\\mathbf{x} - Mùîº[\\mathbf{x}])(M\\mathbf{x} - Mùîº[\\mathbf{x}])^T] \\\\\n",
        "&= ùîº[(M(\\mathbf{x} - \\mu_{\\mathbf{x}}))(M(\\mathbf{x} - \\mu_{\\mathbf{x}}))^T] \\\\\n",
        "&= \\quad ...\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc7abf4c",
      "metadata": {
        "id": "cc7abf4c"
      },
      "source": [
        "# Ordinary least squares covariance proof\n",
        "For an ordinary least squares problem we are solving for the parameters $x$ that minimize the sum of squared residuals $||Ax -b||^2$ where $A$ is a fixed matrix of independent variables and $b$ is a vector of noisy dependent variables. Dependent variables are uncorrelated and have the same variance i.e.:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{b} & \\sim \\mathcal{N}(0, \\Sigma) \\\\\n",
        "\\Sigma & = \\sigma^2 I\n",
        "\\end{aligned}\n",
        "$$\n",
        "The solution to the ordinary least squares problem is obtained through normal equations:\n",
        "$$\n",
        "\\mathbf{x^*} = (A^TA)^{-1}A^T\\mathbf{b}\n",
        "$$\n",
        "We want to know what is the covariance $cov(\\mathbf{x^*})$ of the solution.\n",
        "\n",
        "We can think of the solution $\\mathbf{x^*}$ as a random variable $\\mathbf{b}$ being transformed by a linear transform $M = (A^TA)^{-1}A^T$.\n",
        "We can use the property of covariance of a random variable transformed by a linear transform:\n",
        "$$\n",
        "\\begin{align*}\n",
        "M                  & = (A^TA)^{-1}A^T \\\\\n",
        "\\mathbf{x^*}       & = M\\mathbf{b} \\\\\n",
        "cov(\\mathbf{b})    & = \\Sigma \\\\\n",
        "cov(\\mathbf{x^*})  & = M \\Sigma M^T \\\\\n",
        "                   & = (A^TA)^{-1}A^T \\Sigma ((A^TA)^{-1}A^T)^T \\\\\n",
        "((A^TA)^{-1}A^T)^T & = A (A^TA)^{-T} \\\\\n",
        "                   & = A (A^TA)^{-1}\n",
        "\\end{align*}\n",
        "$$\n",
        "The last equality holds since $A^TA$ is a symmetric matrix and inverse of a symmetric matrix is also a symmetric matrix [[proof](https://math.stackexchange.com/questions/325082/is-the-inverse-of-a-symmetric-matrix-also-symmetric)]. This gives us:\n",
        "$$\n",
        "\\begin{align*}\n",
        "cov(\\mathbf{x^*})  & = (A^TA)^{-1}A^T \\Sigma A (A^TA)^{-1}\n",
        "\\end{align*}\n",
        "$$\n",
        "This expression can be simplified further by taking advantage of the fact that $\\Sigma = \\sigma^2 * I$. The middle part of the expression can be simplified as follows:\n",
        "$$\n",
        "\\begin{align*}\n",
        "A^T \\Sigma A & = A^T \\sigma^2 I A \\\\\n",
        "             & = A^T \\sigma^2 A \\\\\n",
        "             & = \\sigma^2 A^T A \\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "Plugging this back we get:\n",
        "$$\n",
        "\\begin{align*}\n",
        "cov(\\mathbf{x^*})  & = (A^TA)^{-1} \\sigma^2 (A^T A) (A^TA)^{-1} \\\\\n",
        "                   & = (A^TA)^{-1} \\sigma^2\n",
        "\\end{align*}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ab2fa9",
      "metadata": {
        "id": "69ab2fa9"
      },
      "source": [
        "# Weighted least squares covariance proof\n",
        "For weighted least squares the covariance of the measurement noise is a diagonal matrix:\n",
        "$$\n",
        "\\mathbf{b} \\sim \\mathcal{N}(0, \\Sigma) \\\\\n",
        "\\Sigma =\n",
        "\\begin{bmatrix}\n",
        "\\sigma_0^2 & \\cdots & 0 \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "0 & \\cdots & \\sigma_n^2 \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "$$\n",
        "And the solution to the weighted least squares problem is:\n",
        "$$\n",
        "x^* = (A^T W A)^{-1}A^T Wb \\\\\n",
        "$$\n",
        "where $W = \\Sigma^{-1}$.\n",
        "\n",
        "Similarly to ordinary least squares we obtain the expression for the covariance of $x^*$ by taking advantage of the property of random variables transformed by a linear transform:\n",
        "$$cov(M\\mathbf{x}) = M cov(\\mathbf{x}) M^T$$\n",
        "\n",
        "For weighted least squares we have:\n",
        "$$\n",
        "\\begin{align*}\n",
        "M                  & = (A^T W A)^{-1}A^T W \\\\\n",
        "\\mathbf{x^*}       & = M\\mathbf{b} \\\\\n",
        "cov(\\mathbf{b})    & = \\Sigma \\\\\n",
        "cov(\\mathbf{x^*})  & = M \\Sigma M^T \\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "Since both $W$ and $A^TWA$ are symmetric we have:\n",
        "$$\n",
        "\\begin{align*}\n",
        "M^T                & = ((A^T W A)^{-1}A^T W)^T \\\\\n",
        "                   & = W^TA(A^T W A)^{-T} \\\\\n",
        "                   & = WA(A^T W A)^{-1} \\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "Plugging back into expression for covariance of $x^*$ we get:\n",
        "$$\n",
        "\\begin{align*}\n",
        "cov(\\mathbf{x^*})  & = M \\Sigma M^T \\\\\n",
        "                   & = (A^T W A)^{-1}A^T W \\Sigma WA(A^T W A)^{-1} \\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "Since $W = \\Sigma^{-1}$ this simplifies to:\n",
        "$$\n",
        "\\begin{align*}\n",
        "cov(\\mathbf{x^*}) & = (A^T \\Sigma^{-1} A)^{-1}A^T \\Sigma^{-1} \\Sigma \\Sigma^{-1}A(A^T \\Sigma^{-1} A)^{-1} \\\\\n",
        "                  & = (A^T \\Sigma^{-1} A)^{-1}(A^T \\Sigma^{-1} A)(A^T \\Sigma^{-1} A)^{-1} \\\\\n",
        "                  & = (A^T \\Sigma^{-1} A)^{-1} \\\\\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vEOLAMi8gGFF"
      },
      "id": "vEOLAMi8gGFF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}